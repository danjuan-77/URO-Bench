# VocalNet å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡å¤„ç†æ–¹æ¡ˆ

## ğŸ¯ æ”¹è¿›ç›®æ ‡

è§£å†³VocalNetåœ¨å¤šè½®å¯¹è¯ä¸­ç¼ºä¹ä¸Šä¸‹æ–‡è®°å¿†çš„é—®é¢˜ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿç†è§£å®Œæ•´çš„å¯¹è¯å†å²ï¼Œæä¾›æ›´è¿è´¯çš„å“åº”ã€‚

## ğŸ”„ å®ç°æ–¹æ¡ˆ

### åŸå§‹é—®é¢˜
```python
# åŸå§‹å®ç° - æ¯è½®ç‹¬ç«‹å¤„ç†
messages = [{
    'role': 'user', 
    'content': '<speech>', 
    'path': input_audio
}]
```

**é—®é¢˜**ï¼šæ¯è½®å¯¹è¯éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œæ¨¡å‹æ— æ³•ç†è§£ä¹‹å‰çš„å¯¹è¯å†…å®¹ã€‚

### æ”¹è¿›æ–¹æ¡ˆï¼šASRå†å² + åŠ©æ‰‹å“åº”æ‹¼æ¥

#### 1. æ ¸å¿ƒæ€è·¯
- **ASRè½¬å½•ç”¨æˆ·å†å²**ï¼šä½¿ç”¨Whisperå¯¹ä¹‹å‰è½®æ¬¡çš„ç”¨æˆ·éŸ³é¢‘è¿›è¡Œå®æ—¶è½¬å½•
- **åŠ©æ‰‹å“åº”æ–‡æœ¬å†å²**ï¼šä¿å­˜æ¨¡å‹ä¹‹å‰ç”Ÿæˆçš„æ–‡æœ¬å“åº”
- **ä¸Šä¸‹æ–‡æ‹¼æ¥**ï¼šå°†ASRæ–‡æœ¬å’ŒåŠ©æ‰‹å“åº”æŒ‰æ—¶é—´é¡ºåºæ‹¼æ¥æˆå¯¹è¯å†å²
- **æ³¨å…¥æ¨¡å‹**ï¼šå°†å¯¹è¯å†å²ä½œä¸ºæ–‡æœ¬ä¸Šä¸‹æ–‡æ³¨å…¥åˆ°å½“å‰è¾“å…¥ä¸­

#### 2. æ•°æ®æµç¨‹

```
è½®æ¬¡1: ç”¨æˆ·éŸ³é¢‘1 â†’ ASRè½¬å½•1 â†’ VocalNet â†’ åŠ©æ‰‹å“åº”1
è½®æ¬¡2: ç”¨æˆ·éŸ³é¢‘2 + [ASRè½¬å½•1 + åŠ©æ‰‹å“åº”1] â†’ VocalNet â†’ åŠ©æ‰‹å“åº”2  
è½®æ¬¡3: ç”¨æˆ·éŸ³é¢‘3 + [ASRè½¬å½•1,2 + åŠ©æ‰‹å“åº”1,2] â†’ VocalNet â†’ åŠ©æ‰‹å“åº”3
```

#### 3. å®ç°ç»†èŠ‚

##### A. ASRè½¬å½•åŠŸèƒ½
```python
def get_asr_transcription(audio_path):
    """ä½¿ç”¨Whisperå®æ—¶è½¬å½•éŸ³é¢‘"""
    import whisper
    
    # ç¼“å­˜æ¨¡å‹ä»¥æé«˜æ•ˆç‡
    if not hasattr(get_asr_transcription, 'model'):
        get_asr_transcription.model = whisper.load_model("large-v3")
    
    result = get_asr_transcription.model.transcribe(audio_path)
    return result["text"].strip()
```

##### B. ä¸Šä¸‹æ–‡æ„å»º
```python
def build_conversation_context(conversation_history, max_turns=3):
    """æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡"""
    if not conversation_history:
        return ""
    
    # ä½¿ç”¨æœ€è¿‘3è½®å¯¹è¯é¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
    recent_history = conversation_history[-max_turns:]
    
    context_parts = []
    for turn in recent_history:
        round_num = turn.get('round', 1)
        
        # ASRè½¬å½•çš„ç”¨æˆ·è¾“å…¥
        user_asr_text = turn.get('asr_text', '').strip()
        if not user_asr_text:
            user_asr_text = turn.get('source_text', '').strip()
        
        # åŠ©æ‰‹å“åº”æ–‡æœ¬
        assistant_text = turn.get('output_text', '').strip()
        
        if user_asr_text:
            context_parts.append(f"è½®æ¬¡{round_num} ç”¨æˆ·: {user_asr_text}")
        if assistant_text:
            context_parts.append(f"è½®æ¬¡{round_num} åŠ©æ‰‹: {assistant_text}")
    
    return "\n".join(context_parts)
```

##### C. ä¸Šä¸‹æ–‡æ³¨å…¥
```python
def respond(input_audio, output_path, conversation_history=None):
    """å¸¦ä¸Šä¸‹æ–‡çš„å“åº”ç”Ÿæˆ"""
    
    # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
    context_prompt = build_conversation_context(conversation_history)
    
    # æ³¨å…¥ä¸Šä¸‹æ–‡åˆ°æ¨¡å‹è¾“å…¥
    if context_prompt:
        messages = [{
            'role': 'user', 
            'content': f'<speech>\n\nå¯¹è¯å†å²:\n{context_prompt}\n\nå½“å‰ç”¨æˆ·:', 
            'path': input_audio
        }]
    else:
        messages = [{
            'role': 'user', 
            'content': '<speech>', 
            'path': input_audio
        }]
    
    return vocalnet_model(messages)
```

##### D. ä¸»è¦å¯¹è¯å¾ªç¯
```python
# ç»´æŠ¤å¯¹è¯å†å²
conversation_history = []

for turn in dialogue:
    # 1. ASRè½¬å½•å½“å‰ç”¨æˆ·è¾“å…¥
    current_asr_text = get_asr_transcription(input_path)
    
    # 2. ä½¿ç”¨å†å²ä¸Šä¸‹æ–‡ç”Ÿæˆå“åº”
    response = respond(input_path, output_path, conversation_history)
    
    # 3. ä¿å­˜å½“å‰è½®æ¬¡åˆ°å†å²
    current_turn = {
        "round": turn["round"],
        "source_text": turn["source_text"],      # åŸå§‹æ–‡æœ¬
        "asr_text": current_asr_text,            # ASRè½¬å½•
        "output_text": response.strip(),         # åŠ©æ‰‹å“åº”
        "target_text": turn["target_text"]
    }
    
    conversation_history.append(current_turn)
```

## ğŸ“Š ä¸Šä¸‹æ–‡æ ¼å¼ç¤ºä¾‹

### è¾“å…¥æ ¼å¼
```
å¯¹è¯å†å²:
è½®æ¬¡1 ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²
è½®æ¬¡1 åŠ©æ‰‹: æ‚¨å¥½ï¼äººå·¥æ™ºèƒ½çš„å‘å±•å¯ä»¥è¿½æº¯åˆ°1950å¹´ä»£...
è½®æ¬¡2 ç”¨æˆ·: é‚£æ·±åº¦å­¦ä¹ æ˜¯ä»€ä¹ˆæ—¶å€™å¼€å§‹å…´èµ·çš„ï¼Ÿ
è½®æ¬¡2 åŠ©æ‰‹: æ·±åº¦å­¦ä¹ çš„å…´èµ·ä¸»è¦åœ¨2010å¹´ä»£...

å½“å‰ç”¨æˆ·: [éŸ³é¢‘è¾“å…¥]
```

### æ•°æ®ç»“æ„
```json
{
  "round": 3,
  "source_text": "åŸå§‹æ ‡æ³¨æ–‡æœ¬",
  "asr_text": "Whisperè½¬å½•æ–‡æœ¬", 
  "output_text": "VocalNetç”Ÿæˆå“åº”",
  "target_text": "æœŸæœ›å“åº”æ–‡æœ¬"
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. Whisperæ¨¡å‹ç¼“å­˜
```python
# ç¼“å­˜Whisperæ¨¡å‹é¿å…é‡å¤åŠ è½½
if not hasattr(get_asr_transcription, 'model'):
    get_asr_transcription.model = whisper.load_model("large-v3")
```

### 2. ä¸Šä¸‹æ–‡é•¿åº¦æ§åˆ¶
```python
# åªä½¿ç”¨æœ€è¿‘3è½®å¯¹è¯ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
recent_history = conversation_history[-3:]
```

### 3. å¼‚å¸¸å¤„ç†
```python
try:
    current_asr_text = get_asr_transcription(input_path)
except Exception as e:
    # é™çº§åˆ°åŸå§‹æ–‡æœ¬
    current_asr_text = turn.get("source_text", "")
```

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### 1. ç¯å¢ƒå˜é‡è®¾ç½®
```bash
export WHISPER_MODEL_PATH="/path/to/whisper-large-v3"  # å¯é€‰
```

### 2. è¿è¡Œå¤šè½®å¯¹è¯æ¨ç†
```bash
python examples/VocalNet-test/inference_multi.py \
    --dataset /path/to/URO-Bench-data/pro/MtBenchEval-en/test.jsonl \
    --output_dir ./output_with_context
```

### 3. æ—¥å¿—è¾“å‡ºç¤ºä¾‹
```
INFO - Getting ASR transcription for round 1...
INFO - Generating response with context (history length: 0)...
INFO - Conversation 1, Round 1
INFO -   Input (Original): Tell me about artificial intelligence
INFO -   Input (ASR): Tell me about artificial intelligence
INFO -   Output: Artificial intelligence (AI) refers to...

INFO - Getting ASR transcription for round 2...
INFO - Generating response with context (history length: 1)...
INFO - Conversation 1, Round 2  
INFO -   Input (Original): What about deep learning?
INFO -   Input (ASR): What about deep learning?
INFO -   Output: Based on our previous discussion about AI, deep learning...
```

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

1. **ä¸Šä¸‹æ–‡ä¸€è‡´æ€§**ï¼šæ¨¡å‹èƒ½å¤Ÿç†è§£ä¹‹å‰çš„å¯¹è¯å†…å®¹
2. **æŒ‡ä»£æ¶ˆè§£**ï¼šèƒ½å¤Ÿæ­£ç¡®ç†è§£"å®ƒ"ã€"é‚£ä¸ª"ç­‰æŒ‡ä»£è¯
3. **è¯é¢˜è¿è´¯æ€§**ï¼šå“åº”èƒ½å¤Ÿä¸å¯¹è¯ä¸»é¢˜ä¿æŒä¸€è‡´
4. **æ¸è¿›å¼å¯¹è¯**ï¼šæ”¯æŒå±‚å±‚æ·±å…¥çš„é—®ç­”æ¨¡å¼

## ğŸ›ï¸ å¯è°ƒå‚æ•°

- `max_turns`: ä¸Šä¸‹æ–‡åŒ…å«çš„æœ€å¤§è½®æ¬¡æ•°ï¼ˆé»˜è®¤3ï¼‰
- ASRæ¨¡å‹é€‰æ‹©ï¼šwhisper-large-v3 vs å…¶ä»–ç‰ˆæœ¬
- ä¸Šä¸‹æ–‡æ ¼å¼ï¼šä¸­æ–‡ vs è‹±æ–‡æç¤º
- é™çº§ç­–ç•¥ï¼šASRå¤±è´¥æ—¶ä½¿ç”¨åŸå§‹æ–‡æœ¬

## ğŸš€ è¿›ä¸€æ­¥ä¼˜åŒ–æ–¹å‘

1. **æ™ºèƒ½ä¸Šä¸‹æ–‡é€‰æ‹©**ï¼šæ ¹æ®ç›¸å…³æ€§åŠ¨æ€é€‰æ‹©å†å²è½®æ¬¡
2. **å¤šæ¨¡æ€ä¸Šä¸‹æ–‡**ï¼šç»“åˆéŸ³é¢‘ç‰¹å¾å’Œæ–‡æœ¬ä¿¡æ¯
3. **å¯¹è¯çŠ¶æ€è·Ÿè¸ª**ï¼šç»´æŠ¤å®ä½“å’Œä¸»é¢˜çš„æ˜¾å¼çŠ¶æ€
4. **ä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡**ï¼šæ ¹æ®ç”¨æˆ·ç‰¹ç‚¹è°ƒæ•´ä¸Šä¸‹æ–‡æ ¼å¼


